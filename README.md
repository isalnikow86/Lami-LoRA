# Lami-LoRA â€” LeoLM 7B LoRA Training (Klexikon Dataset)

## ğŸ” Overview

This repo trains a **LoRA adapter** on the **LeoLM/leo-hessianai-7b** model using **Klexikon data** (German children's encyclopedia) on **H100** GPU.

## ğŸš€ Steps to run training

### 1ï¸âƒ£ Clone repo & prepare environment

```bash
git clone https://github.com/isalinkow86/Lami-LoRA.git
cd Lami-LoRA
pip install -r requirements.txt
