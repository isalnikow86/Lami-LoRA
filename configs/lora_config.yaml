base_model: LeoLM/leo-hessianai-7b
output_dir: lora-outputs/
learning_rate: 5e-5
batch_size: 32
num_train_epochs: 3
logging_steps: 10
save_steps: 100
